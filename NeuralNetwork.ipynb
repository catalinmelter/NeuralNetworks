{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.utils.generic_utils import Progbar\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_digits(n_class=10, return_X_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X['images'], X['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: %d 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23c236eaac8>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 100\n",
    "print('Target: %d', y[idx])\n",
    "plt.imshow(X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8), (1797,))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1] * X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(X)\n",
    "X = X / max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "y = lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(y.shape[0], y.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10, 1)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    @staticmethod\n",
    "    def fn(z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    @staticmethod\n",
    "    def prime(z):\n",
    "        return Sigmoid.fn(z)*(1-Sigmoid.fn(z))\n",
    "    \n",
    "class Softmax:\n",
    "    @staticmethod\n",
    "    def fn(z):\n",
    "        return np.nan_to_num(np.exp(z)/np.sum(np.exp(z)))\n",
    "    @staticmethod\n",
    "    def prime(z):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantifyCost:\n",
    "    @staticmethod\n",
    "    def fn(y, a):\n",
    "        return np.linalg.norm(a-y)**2\n",
    "    @staticmethod\n",
    "    def delta(y, a):\n",
    "        return (a-y)\n",
    "    @staticmethod\n",
    "    def loss(y_true, y_pred):\n",
    "        return 0.5 * (1/len(y_true)) * np.sum([QuantifyCost.fn(y, a) for y, a in zip(y_true, y_pred)])\n",
    "    \n",
    "class CrossEntropyCost:\n",
    "    @staticmethod\n",
    "    def fn(y, a):\n",
    "        return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))\n",
    "    @staticmethod\n",
    "    def delta(y, a):\n",
    "        return (a-y)\n",
    "    @staticmethod\n",
    "    def loss(y_true, y_pred):\n",
    "        return  (1/len(y_true)) * np.sum([CrossEntropyCost.fn(y, a) for y, a in zip(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        eq = np.argmax(y_true, axis=1).squeeze() == np.argmax(y_pred, axis=1).squeeze()\n",
    "        return list(eq).count(True) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightsInit:\n",
    "    @staticmethod\n",
    "    def zeros(shape):\n",
    "        return np.zeros(shape)\n",
    "    @staticmethod\n",
    "    def randn(shape):\n",
    "        return np.random.randn(*shape)\n",
    "    @staticmethod\n",
    "    def normal(shape):\n",
    "        return np.random.normal(loc=0.0, scale=(1/np.sqrt(shape[0])), size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, shape, winit, binit, fn):\n",
    "        self.shape = shape\n",
    "        self.weights = winit((shape[1], shape[0]))\n",
    "        self.biases = binit((shape[1], 1))\n",
    "        self.fn = fn\n",
    "        self.wdelta, self.bdelta = 0, 0\n",
    "        \n",
    "    def forward(self, a):\n",
    "        self.last_input_shape = a.shape\n",
    "        a = a.reshape(np.product(a.shape), 1)\n",
    "            \n",
    "        self.last_input = a\n",
    "        z = np.dot(self.weights, a) + self.biases\n",
    "        self.last_z = z\n",
    "        \n",
    "        return self.fn.fn(z), z\n",
    "    \n",
    "    def backprop(self, d_L_d_out):\n",
    "        delta = d_L_d_out * self.fn.prime(self.last_z)\n",
    "        self.bdelta += delta\n",
    "        self.wdelta += np.dot(delta, self.last_input.T)\n",
    "        d_L_d_inputs = np.dot(self.weights.T, d_L_d_out)\n",
    "        return d_L_d_inputs.reshape(self.last_input_shape)\n",
    "        \n",
    "    def update(self, eta, lr, batch_size, size, norm):\n",
    "        self.biases = self.biases - (eta/batch_size) * self.bdelta\n",
    "        self.weights = self.weights - (eta/batch_size) * self.wdelta\n",
    "        if norm == 'l2':\n",
    "            self.weights = self.weights - lr * (eta/size) * self.weights\n",
    "        elif norm == 'l1':\n",
    "            self.weights = self.weights - lr * (eta/size) * np.sign(self.weights)\n",
    "        self.wdelta, self.bdelta = 0, 0\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, layers, fcost):\n",
    "        self.layers = layers\n",
    "        self.fcost = fcost\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "        \n",
    "    def feed_forward(self, a):\n",
    "        for layer in self.layers:\n",
    "            a, _ = layer.forward(a)\n",
    "        return a\n",
    "    \n",
    "    def backprop(self, x, y):\n",
    "        a = x\n",
    "        for layer in self.layers:\n",
    "            a, _ = layer.forward(a)\n",
    "        \n",
    "        d_L_d_out = self.fcost.delta(y, a)\n",
    "        for i in range(1, len(self) + 1):\n",
    "            d_L_d_out = self.layers[-i].backprop(d_L_d_out)\n",
    "            \n",
    "        return a\n",
    "            \n",
    "    def update_batch(self, X_batch, y_batch, eta, lr, size, norm):\n",
    "        y_batch_pred = []\n",
    "        for x, y in zip(X_batch, y_batch):\n",
    "            y_pred = self.backprop(x, y)\n",
    "            y_batch_pred.append(y_pred)\n",
    "            \n",
    "        for layer in self.layers:\n",
    "            layer.update(eta, lr, len(y_batch), size, norm)\n",
    "            \n",
    "        return y_batch_pred\n",
    "    \n",
    "    def evaluate(self, y_true, y_pred, lr, norm):\n",
    "        loss = self.fcost.loss(y_true, y_pred)\n",
    "        if norm == 'l2':\n",
    "            loss += 0.5 * (lr/len(y_true)) * np.sum([np.sum(layer.weights**2) for layer in self.layers])\n",
    "        elif norm == 'l1':\n",
    "            loss += (lr/len(y_true)) * np.sum([np.sum(layer.weights) for layer in self.layers])\n",
    "        acc = Metrics.accuracy(y_true, y_pred)\n",
    "        return loss, acc\n",
    "    \n",
    "    def SGD(self, X_train, y_train, epochs, batch_size, eta, lr=1e-3, validation_data=None, norm=None):\n",
    "        for epoch in range(epochs):\n",
    "            y_train_pred = []\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                y_batch_pred = self.update_batch(X_train[i:i+batch_size], y_train[i:i+batch_size], eta, lr, len(X_train), norm)\n",
    "                y_train_pred.extend(y_batch_pred)\n",
    "            \n",
    "            loss, acc = self.evaluate(y_train, y_train_pred, lr, norm)\n",
    "            if validation_data:\n",
    "                X_test, y_test = validation_data\n",
    "                y_test_pred = [self.feed_forward(x) for x in X_test]\n",
    "                val_loss, val_acc = self.evaluate(y_test, y_test_pred, lr, norm)\n",
    "                print('Epoch: %d - val_loss: %0.4f - val_acc: %0.4f' % (epoch, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - val_loss: 0.9932 - val_acc: 0.9056\n",
      "Epoch: 1 - val_loss: 0.7058 - val_acc: 0.9306\n",
      "Epoch: 2 - val_loss: 0.5807 - val_acc: 0.9472\n",
      "Epoch: 3 - val_loss: 0.5053 - val_acc: 0.9500\n",
      "Epoch: 4 - val_loss: 0.4534 - val_acc: 0.9556\n",
      "Epoch: 5 - val_loss: 0.4150 - val_acc: 0.9639\n",
      "Epoch: 6 - val_loss: 0.3848 - val_acc: 0.9694\n",
      "Epoch: 7 - val_loss: 0.3604 - val_acc: 0.9639\n",
      "Epoch: 8 - val_loss: 0.3399 - val_acc: 0.9667\n",
      "Epoch: 9 - val_loss: 0.3226 - val_acc: 0.9694\n",
      "Epoch: 10 - val_loss: 0.3078 - val_acc: 0.9694\n",
      "Epoch: 11 - val_loss: 0.2951 - val_acc: 0.9722\n",
      "Epoch: 12 - val_loss: 0.2842 - val_acc: 0.9750\n",
      "Epoch: 13 - val_loss: 0.2747 - val_acc: 0.9750\n",
      "Epoch: 14 - val_loss: 0.2663 - val_acc: 0.9750\n",
      "Epoch: 15 - val_loss: 0.2587 - val_acc: 0.9750\n",
      "Epoch: 16 - val_loss: 0.2520 - val_acc: 0.9750\n",
      "Epoch: 17 - val_loss: 0.2460 - val_acc: 0.9750\n",
      "Epoch: 18 - val_loss: 0.2408 - val_acc: 0.9750\n",
      "Epoch: 19 - val_loss: 0.2362 - val_acc: 0.9778\n",
      "Epoch: 20 - val_loss: 0.2322 - val_acc: 0.9778\n",
      "Epoch: 21 - val_loss: 0.2287 - val_acc: 0.9778\n",
      "Epoch: 22 - val_loss: 0.2256 - val_acc: 0.9778\n",
      "Epoch: 23 - val_loss: 0.2227 - val_acc: 0.9778\n",
      "Epoch: 24 - val_loss: 0.2201 - val_acc: 0.9806\n",
      "Epoch: 25 - val_loss: 0.2176 - val_acc: 0.9806\n",
      "Epoch: 26 - val_loss: 0.2153 - val_acc: 0.9806\n",
      "Epoch: 27 - val_loss: 0.2132 - val_acc: 0.9806\n",
      "Epoch: 28 - val_loss: 0.2112 - val_acc: 0.9833\n",
      "Epoch: 29 - val_loss: 0.2094 - val_acc: 0.9833\n",
      "Epoch: 30 - val_loss: 0.2075 - val_acc: 0.9833\n",
      "Epoch: 31 - val_loss: 0.2053 - val_acc: 0.9833\n",
      "Epoch: 32 - val_loss: 0.2029 - val_acc: 0.9833\n",
      "Epoch: 33 - val_loss: 0.2004 - val_acc: 0.9833\n",
      "Epoch: 34 - val_loss: 0.1981 - val_acc: 0.9833\n",
      "Epoch: 35 - val_loss: 0.1960 - val_acc: 0.9833\n",
      "Epoch: 36 - val_loss: 0.1940 - val_acc: 0.9833\n",
      "Epoch: 37 - val_loss: 0.1920 - val_acc: 0.9833\n",
      "Epoch: 38 - val_loss: 0.1900 - val_acc: 0.9833\n",
      "Epoch: 39 - val_loss: 0.1881 - val_acc: 0.9833\n",
      "Epoch: 40 - val_loss: 0.1862 - val_acc: 0.9833\n",
      "Epoch: 41 - val_loss: 0.1844 - val_acc: 0.9833\n",
      "Epoch: 42 - val_loss: 0.1826 - val_acc: 0.9806\n",
      "Epoch: 43 - val_loss: 0.1808 - val_acc: 0.9806\n",
      "Epoch: 44 - val_loss: 0.1789 - val_acc: 0.9806\n",
      "Epoch: 45 - val_loss: 0.1768 - val_acc: 0.9806\n",
      "Epoch: 46 - val_loss: 0.1746 - val_acc: 0.9806\n",
      "Epoch: 47 - val_loss: 0.1722 - val_acc: 0.9806\n",
      "Epoch: 48 - val_loss: 0.1701 - val_acc: 0.9806\n",
      "Epoch: 49 - val_loss: 0.1684 - val_acc: 0.9806\n",
      "Epoch: 50 - val_loss: 0.1669 - val_acc: 0.9806\n",
      "Epoch: 51 - val_loss: 0.1656 - val_acc: 0.9806\n",
      "Epoch: 52 - val_loss: 0.1644 - val_acc: 0.9806\n",
      "Epoch: 53 - val_loss: 0.1633 - val_acc: 0.9806\n",
      "Epoch: 54 - val_loss: 0.1622 - val_acc: 0.9806\n",
      "Epoch: 55 - val_loss: 0.1613 - val_acc: 0.9806\n",
      "Epoch: 56 - val_loss: 0.1604 - val_acc: 0.9806\n",
      "Epoch: 57 - val_loss: 0.1596 - val_acc: 0.9806\n",
      "Epoch: 58 - val_loss: 0.1587 - val_acc: 0.9806\n",
      "Epoch: 59 - val_loss: 0.1579 - val_acc: 0.9806\n",
      "Epoch: 60 - val_loss: 0.1570 - val_acc: 0.9806\n",
      "Epoch: 61 - val_loss: 0.1562 - val_acc: 0.9806\n",
      "Epoch: 62 - val_loss: 0.1554 - val_acc: 0.9806\n",
      "Epoch: 63 - val_loss: 0.1546 - val_acc: 0.9806\n",
      "Epoch: 64 - val_loss: 0.1538 - val_acc: 0.9806\n",
      "Epoch: 65 - val_loss: 0.1530 - val_acc: 0.9806\n",
      "Epoch: 66 - val_loss: 0.1523 - val_acc: 0.9806\n",
      "Epoch: 67 - val_loss: 0.1516 - val_acc: 0.9806\n",
      "Epoch: 68 - val_loss: 0.1509 - val_acc: 0.9806\n",
      "Epoch: 69 - val_loss: 0.1502 - val_acc: 0.9806\n",
      "Epoch: 70 - val_loss: 0.1496 - val_acc: 0.9806\n",
      "Epoch: 71 - val_loss: 0.1490 - val_acc: 0.9806\n",
      "Epoch: 72 - val_loss: 0.1485 - val_acc: 0.9806\n",
      "Epoch: 73 - val_loss: 0.1479 - val_acc: 0.9806\n",
      "Epoch: 74 - val_loss: 0.1474 - val_acc: 0.9806\n",
      "Epoch: 75 - val_loss: 0.1468 - val_acc: 0.9806\n",
      "Epoch: 76 - val_loss: 0.1462 - val_acc: 0.9806\n",
      "Epoch: 77 - val_loss: 0.1457 - val_acc: 0.9806\n",
      "Epoch: 78 - val_loss: 0.1451 - val_acc: 0.9806\n",
      "Epoch: 79 - val_loss: 0.1445 - val_acc: 0.9833\n",
      "Epoch: 80 - val_loss: 0.1439 - val_acc: 0.9833\n",
      "Epoch: 81 - val_loss: 0.1434 - val_acc: 0.9833\n",
      "Epoch: 82 - val_loss: 0.1428 - val_acc: 0.9833\n",
      "Epoch: 83 - val_loss: 0.1423 - val_acc: 0.9833\n",
      "Epoch: 84 - val_loss: 0.1418 - val_acc: 0.9833\n",
      "Epoch: 85 - val_loss: 0.1413 - val_acc: 0.9833\n",
      "Epoch: 86 - val_loss: 0.1407 - val_acc: 0.9833\n",
      "Epoch: 87 - val_loss: 0.1403 - val_acc: 0.9833\n",
      "Epoch: 88 - val_loss: 0.1398 - val_acc: 0.9833\n",
      "Epoch: 89 - val_loss: 0.1393 - val_acc: 0.9833\n",
      "Epoch: 90 - val_loss: 0.1389 - val_acc: 0.9833\n",
      "Epoch: 91 - val_loss: 0.1384 - val_acc: 0.9833\n",
      "Epoch: 92 - val_loss: 0.1380 - val_acc: 0.9833\n",
      "Epoch: 93 - val_loss: 0.1375 - val_acc: 0.9833\n",
      "Epoch: 94 - val_loss: 0.1371 - val_acc: 0.9833\n",
      "Epoch: 95 - val_loss: 0.1367 - val_acc: 0.9833\n",
      "Epoch: 96 - val_loss: 0.1363 - val_acc: 0.9833\n",
      "Epoch: 97 - val_loss: 0.1359 - val_acc: 0.9833\n",
      "Epoch: 98 - val_loss: 0.1356 - val_acc: 0.9833\n",
      "Epoch: 99 - val_loss: 0.1352 - val_acc: 0.9833\n"
     ]
    }
   ],
   "source": [
    "deep0 = Dense(shape=(64, 128), winit=WeightsInit.normal, binit=WeightsInit.zeros, fn=Sigmoid)\n",
    "deep1 = Dense(shape=(128, 10), winit=WeightsInit.normal, binit=WeightsInit.zeros, fn=Sigmoid)\n",
    "model = Model(layers=[deep0, deep1], fcost=CrossEntropyCost)\n",
    "\n",
    "model.SGD(X_train, y_train, epochs=100, batch_size=10, eta=1, lr=1e-3, validation_data=(X_test, y_test), norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, filters, winit, fn):\n",
    "        self.filters = filters\n",
    "        self.weights = winit((filters, 3, 3))\n",
    "        self.fn = fn\n",
    "        self.wdelta = np.zeros(self.weights.shape)\n",
    "    \n",
    "    def iterate_regions(self, a):\n",
    "        h, w = a.shape\n",
    "        for i in range(h - 2):\n",
    "            for j in range(w - 2):\n",
    "                im_region = a[i:(i + 3), j:(j + 3)]\n",
    "                yield im_region, i, j\n",
    "        \n",
    "    def forward(self, a):\n",
    "        self.last_input = a\n",
    "        h, w = a.shape\n",
    "        output = np.zeros((h - 2, w - 2, self.filters))\n",
    "        for im_region, i, j in self.iterate_regions(a):\n",
    "            output[i, j] = np.sum(im_region * self.weights, axis=(1, 2))\n",
    "        return self.fn.fn(output), output\n",
    "    \n",
    "    def backprop(self, d_L_d_out):\n",
    "        d_L_d_weights = np.zeros(self.weights.shape)\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            for f in range(self.filters):\n",
    "                d_L_d_weights[f] += d_L_d_out[i, j, f] * im_region\n",
    "        self.wdelta += d_L_d_weights\n",
    "    \n",
    "    def update(self, eta, lr, batch_size, size, norm):\n",
    "        self.weights = self.weights - (eta/batch_size) * self.wdelta\n",
    "        if norm == 'l2':\n",
    "            self.weights = self.weights - lr * (eta/size) * self.weights\n",
    "        elif norm == 'l1':\n",
    "            self.weights = self.weights - lr * (eta/size) * np.sign(self.weights)\n",
    "        self.wdelta = np.zeros(self.weights.shape)\n",
    "        \n",
    "class MaxPool2:\n",
    "    def __init__(self):\n",
    "        self.weights = 0\n",
    "        \n",
    "    def iterate_regions(self, a):\n",
    "        h, w, _ = a.shape\n",
    "        new_h = h // 2\n",
    "        new_w = w // 2\n",
    "        for i in range(new_h):\n",
    "            for j in range(new_w):\n",
    "                im_region = a[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\n",
    "                yield im_region, i, j\n",
    "                \n",
    "    def forward(self, a):\n",
    "        self.last_input = a\n",
    "        h, w, num_filters = a.shape\n",
    "        output = np.zeros((h // 2, w // 2, num_filters))\n",
    "        for im_region, i, j in self.iterate_regions(a):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "        return output, output\n",
    "\n",
    "    def backprop(self, d_L_d_out):\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(0, 1))\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        if im_region[i2, j2, f2] == amax[f2]:\n",
    "                            d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\n",
    "        return d_L_d_input\n",
    "    \n",
    "    def update(self, eta, lr, batch_size, size, norm):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - val_loss: 1.6688 - val_acc: 0.7500\n",
      "Epoch: 1 - val_loss: 1.2567 - val_acc: 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 - val_loss: 1.2798 - val_acc: 0.9111\n",
      "Epoch: 3 - val_loss: 1.4709 - val_acc: 0.9111\n",
      "Epoch: 4 - val_loss: 1.7656 - val_acc: 0.9111\n",
      "Epoch: 5 - val_loss: 2.2396 - val_acc: 0.9194\n",
      "Epoch: 6 - val_loss: 2.8175 - val_acc: 0.9222\n",
      "Epoch: 7 - val_loss: 3.5079 - val_acc: 0.9250\n",
      "Epoch: 8 - val_loss: 4.2746 - val_acc: 0.9306\n",
      "Epoch: 9 - val_loss: 5.1541 - val_acc: 0.9278\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-282-c6550f77d4b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCrossEntropyCost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-258-8df34b40eb1b>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, X_train, y_train, epochs, batch_size, eta, lr, validation_data, norm)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[0my_batch_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[0my_train_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-258-8df34b40eb1b>\u001b[0m in \u001b[0;36mupdate_batch\u001b[1;34m(self, X_batch, y_batch, eta, lr, size, norm)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0my_batch_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[0my_batch_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-258-8df34b40eb1b>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0md_L_d_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-281-16155a9653fa>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mim_region\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterate_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_region\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv2d = Conv2D(filters=3, winit=WeightsInit.normal, fn=Sigmoid)\n",
    "max_pool = MaxPool2()\n",
    "dense = Dense(shape=(6*6*3, 10), winit=WeightsInit.normal, binit=WeightsInit.zeros, fn=Sigmoid)\n",
    "model = Model(layers=[conv2d, dense], fcost=CrossEntropyCost)\n",
    "\n",
    "model.SGD(X_train, y_train, epochs=100, batch_size=10, eta=3, lr=1e-3, validation_data=(X_test, y_test), norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
